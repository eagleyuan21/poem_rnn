{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d612ab",
   "metadata": {},
   "source": [
    "To run this code, simply start running it sequentially. In the sixth code block, you can modify parameters such as the poem starter word and the poem rhyme scheme. Feel free to experiment with those variables.\n",
    "\n",
    "It is important to note that once you've run the code for the first time, in additional runs you only have to run from the sixth code block and onwards to generate more poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c085dea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 16:38:32.649084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 16:38:32.724632: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-10 16:38:33.113626: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/home/eagle/anaconda3/lib/\n",
      "2022-12-10 16:38:33.113664: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/home/eagle/anaconda3/lib/\n",
      "2022-12-10 16:38:33.113667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pronouncing\n",
    "import gensim.downloader\n",
    "import pickle\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fdd45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4ec2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 16:39:08.920282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:08.923637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:08.923737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:08.924070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 16:39:08.924896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:08.925004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:08.925073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:09.232776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:09.232906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:09.232983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 16:39:09.233058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1892 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f8ac0474760>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tokenizer', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# Embedding size\n",
    "embedding_dim = 512\n",
    "# RNN size\n",
    "rnn_units = 1024\n",
    "    \n",
    "model = Model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.load_weights('model_poems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62991e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    \n",
    "    temp = tokenizer.texts_to_sequences(inputs)\n",
    "    if len(temp[0]) == 0:\n",
    "      temp = [[1]]\n",
    "    input_ids = np.array(temp)\n",
    "    predicted_logits, states = self.model(input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    predicted_chars = tokenizer.sequences_to_texts([predicted_ids.numpy()])\n",
    "    \n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00fb4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_with_max_embedding(base_word, context_words):\n",
    "  \n",
    "  all_rhyme_words = pronouncing.rhymes(base_word)\n",
    "\n",
    "  best_count = float('-inf')\n",
    "  best_word = \"\"\n",
    "  for r in all_rhyme_words:\n",
    "    count = 0\n",
    "    seen_content = 1\n",
    "    for c in context_words:\n",
    "      if r in glove_vectors and c[0] in glove_vectors:\n",
    "        count += glove_vectors.similarity(r, c[0])\n",
    "        seen_content += 1\n",
    "    \n",
    "    count = count / seen_content\n",
    "    \n",
    "    \n",
    "    if count >= best_count:\n",
    "      best_word = r\n",
    "      best_count = count\n",
    "\n",
    "  return best_word\n",
    "\n",
    "one_step_model = OneStep(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b94459d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURE STARTER WORD AND RHYME SCHEME HERE\n",
    "# RUN ALL CELLS HERE AND BELOW TO SEE NEW POEMS\n",
    "\n",
    "next_char = ['twas']\n",
    "rhyme_scheme = 'ABABCCDD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af19f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "result = [next_char]\n",
    "\n",
    "breaks = rhyme_scheme.count(\" \")\n",
    "lines = len(rhyme_scheme) - breaks\n",
    "n = 0\n",
    "prev_char = []\n",
    "\n",
    "\n",
    "while n < lines:\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  \n",
    "  if next_char == ['\\n']:\n",
    "    if prev_char != ['\\n']:\n",
    "      result.append(next_char)\n",
    "      n += 1\n",
    "  else:\n",
    "    result.append(next_char)\n",
    "    \n",
    "  prev_char = next_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951ed9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_count = 0\n",
    "rhymes = {}\n",
    "\n",
    "temp_scheme = rhyme_scheme.replace(\" \", \"\")\n",
    "i = 0\n",
    "start_index = 0\n",
    "for i in range(len(result)):\n",
    "  if result[i] == ['\\n']:\n",
    "    rhyme_index = temp_scheme[line_count]\n",
    "    if rhyme_index in rhymes:\n",
    "      base_rhyme_word = rhymes[rhyme_index]\n",
    "      embedding_words = result[start_index:i-1]\n",
    "      rhymed_word = get_rhyme_with_max_embedding(base_rhyme_word[0], embedding_words)\n",
    "      result[i-1] = [rhymed_word]\n",
    "      rhymes[rhyme_index] = result[i-1]\n",
    "      \n",
    "    else:\n",
    "      rhymes[rhyme_index] = result[i-1]\n",
    "    \n",
    "    start_index = i + 1\n",
    "    line_count += 1\n",
    "    \n",
    "    \n",
    "start_index = 0\n",
    "line_count = 0\n",
    "for i in range(len(result)):\n",
    "  if result[i] == ['\\n']:\n",
    "    if rhyme_scheme[line_count] == \" \":\n",
    "        result[start_index - 1] = ['\\n\\n']\n",
    "        \n",
    "    line_count += 1\n",
    "    start_index = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5269093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " twas shaken with a little boy \n",
      " on christmas eve a long time \n",
      " on happy night when she slept and enjoy \n",
      " while each year on happy and have crime \n",
      " our grateful and grim that then hand \n",
      " and in the and \n",
      " the berries on the holly bright \n",
      " and as the ancient voice before the might \n",
      " \n"
     ]
    }
   ],
   "source": [
    "poem = \" \"\n",
    "for l in result:\n",
    "  poem += l[0]\n",
    "  poem += \" \"\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69d961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
