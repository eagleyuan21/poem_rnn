{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEjuMfShLgpu",
    "outputId": "d3b6f151-5559-408d-bfc0-0e9281267ed1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:14.080717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 11:56:14.161341: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-09 11:56:14.541927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/home/eagle/anaconda3/lib/\n",
      "2022-12-09 11:56:14.541964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/home/eagle/anaconda3/lib/\n",
      "2022-12-09 11:56:14.541967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#!pip install pronouncing\n",
    "import pronouncing\n",
    "import gensim.downloader\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u6ycnAngf-VC"
   },
   "outputs": [],
   "source": [
    "#PREPROCESSING\n",
    "\n",
    "\n",
    "training_file_path = \"poems.txt\"\n",
    "\n",
    "f = open(training_file_path, \"r\", encoding=\"utf-8\")\n",
    "content = f.read()# read all contents\n",
    "f.close()  # close the file when you're done\n",
    "\n",
    "#(word,word,word,word,etc.)\n",
    "content = content.lower()\n",
    "content_no_punctuation = \"\"\n",
    "i = 0\n",
    "\n",
    "while i < (len(content)):\n",
    "  if content[i] not in string.punctuation:\n",
    "    content_no_punctuation += content[i]\n",
    "  i += 1\n",
    "\n",
    "content = content_no_punctuation\n",
    "\n",
    "lines = content.splitlines()\n",
    "data = []\n",
    "for l in lines:\n",
    "  sentence = l.split()\n",
    "  sentence.append('\\n')\n",
    "  data.append(sentence)\n",
    "  \n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data)\n",
    "encoded = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "\n",
    "flatten_list = [j for sub in encoded for j in sub]\n",
    "vocab = sorted(set(tokenizer.word_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zlPV6p8uHvYt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:49.514913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.518040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.518136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.518432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 11:56:49.519353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.519460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.519531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.844451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.844573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.844664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 11:56:49.844743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1617 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(flatten_list)\n",
    "\n",
    "seq_length = 200\n",
    "\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7uZrKIPtJ6vn"
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0LO6zfkhf-ek"
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size1 = len(set(flatten_list))\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 512\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tF70dKB5K-zM"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ik5_YhahLR-C"
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xDPsoD9tLSHK"
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nsWik1SXLkmu"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AClshjo-MZxN",
    "outputId": "28374f01-2904-49ce-d380-57ac3c8a34b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:51.574413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2022-12-09 11:56:52.056972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-12-09 11:56:52.125641: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fed293b97a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-09 11:56:52.125668: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2022-12-09 11:56:52.128596: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-09 11:56:52.171815: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-09 11:56:52.172753: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-12-09 11:56:52.172759: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2022-12-09 11:56:52.173191: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/27 [>.............................] - ETA: 1:07 - loss: 9.4206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:52.401740: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-09 11:56:52.547605: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-09 11:56:52.552141: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-09 11:56:52.552160: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-09 11:56:52.556695: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-09 11:56:52.624240: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/27 [=>............................] - ETA: 8s - loss: 9.4169  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:52.976636: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/27 [==>...........................] - ETA: 8s - loss: 9.4110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:53.335635: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/27 [===>..........................] - ETA: 8s - loss: 9.3986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:53.709256: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/27 [====>.........................] - ETA: 8s - loss: 9.3411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:54.085992: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6/27 [=====>........................] - ETA: 7s - loss: 9.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:54.455444: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/27 [======>.......................] - ETA: 7s - loss: 8.6645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:54.818099: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/27 [=======>......................] - ETA: 7s - loss: 8.3637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:55.229290: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/27 [=========>....................] - ETA: 6s - loss: 8.1533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:55.625300: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/27 [==========>...................] - ETA: 6s - loss: 7.9796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:56.001327: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11/27 [===========>..................] - ETA: 6s - loss: 7.8326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:56.390500: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12/27 [============>.................] - ETA: 5s - loss: 7.7183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:56.745376: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13/27 [=============>................] - ETA: 5s - loss: 7.6313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:57.112258: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "14/27 [==============>...............] - ETA: 4s - loss: 7.5361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:57.528710: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "15/27 [===============>..............] - ETA: 4s - loss: 7.4528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:57.931821: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/27 [================>.............] - ETA: 4s - loss: 7.4276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:58.332695: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "17/27 [=================>............] - ETA: 3s - loss: 7.4101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:58.793178: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "18/27 [===================>..........] - ETA: 3s - loss: 7.4105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:59.199865: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "19/27 [====================>.........] - ETA: 3s - loss: 7.3801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:56:59.644797: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "20/27 [=====================>........] - ETA: 2s - loss: 7.3694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:00.022020: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "21/27 [======================>.......] - ETA: 2s - loss: 7.3608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:00.390041: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "22/27 [=======================>......] - ETA: 1s - loss: 7.3483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:00.780445: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "23/27 [========================>.....] - ETA: 1s - loss: 7.3436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:01.163422: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/27 [=========================>....] - ETA: 1s - loss: 7.3334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:01.538272: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "25/27 [==========================>...] - ETA: 0s - loss: 7.3267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:01.934281: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "26/27 [===========================>..] - ETA: 0s - loss: 7.3048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:57:02.327089: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 13s 390ms/step - loss: 7.2853\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 10s 380ms/step - loss: 6.5882\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 10s 355ms/step - loss: 6.4949\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 10s 375ms/step - loss: 6.2135\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 10s 374ms/step - loss: 6.0633\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 10s 378ms/step - loss: 5.9580\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 11s 391ms/step - loss: 5.8652\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 10s 373ms/step - loss: 5.7706\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 10s 365ms/step - loss: 5.6851\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 10s 355ms/step - loss: 5.5990\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 10s 355ms/step - loss: 5.5131\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 10s 355ms/step - loss: 5.4264\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 10s 355ms/step - loss: 5.3393\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 10s 356ms/step - loss: 5.2554\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 10s 356ms/step - loss: 5.1684\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 5.0865\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 5.0033\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.9190\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.8325\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.7496\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.6632\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.5842\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 4.5063\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.4234\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 4.3381\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 4.2497\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 4.1621\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 4.0817\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 4.0044\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 3.9271\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.8494\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 3.7806\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 10s 361ms/step - loss: 3.7178\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.6466\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 10s 357ms/step - loss: 3.5768\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.5092\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.4413\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.3721\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.3099\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 3.2652\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.2227\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.1613\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 3.0581\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 2.9702\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 2.8948\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 10s 363ms/step - loss: 2.8275\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 2.7654\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 2.7075\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 2.6444\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 2.5771\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 10s 364ms/step - loss: 2.5108\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 10s 365ms/step - loss: 2.4515\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 10s 363ms/step - loss: 2.3917\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 2.3300\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 2.2635\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 2.1920\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 10s 367ms/step - loss: 2.1256\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 10s 381ms/step - loss: 2.0632\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 10s 367ms/step - loss: 2.0091\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 10s 361ms/step - loss: 1.9572\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.9067\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 1.8603\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.8183\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 1.7788\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 10s 361ms/step - loss: 1.7403\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.6878\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.6224\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.5557\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.4916\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.4368\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.3849\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.3391\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 1.2951\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.2486\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.2036\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.1549\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 1.1095\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 1.0665\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 1.0273\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.9927\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.9596\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.9247\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.8853\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.8507\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.8204\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.7946\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.7691\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.7477\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 0.7236\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 10s 368ms/step - loss: 0.6995\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.6713\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 0.6517\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 0.6395\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 10s 363ms/step - loss: 0.6249\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 10s 362ms/step - loss: 0.6083\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 10s 362ms/step - loss: 0.5749\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 10s 364ms/step - loss: 0.5429\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 10s 369ms/step - loss: 0.5123\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 10s 367ms/step - loss: 0.4796\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.4496\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OG9DC1Q1MelL"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "\n",
    "  #@tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    \n",
    "    temp = tokenizer.texts_to_sequences(inputs)\n",
    "    if len(temp[0]) == 0:\n",
    "      temp = [[1]]\n",
    "    input_ids = np.array(temp)\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    #predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = tokenizer.sequences_to_texts([predicted_ids.numpy()])\n",
    "    \n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_with_max_embedding(base_word, context_words):\n",
    "  \n",
    "  all_rhyme_words = pronouncing.rhymes(base_word)\n",
    "\n",
    "  best_count = float('-inf')\n",
    "  best_word = \"\"\n",
    "  for r in all_rhyme_words:\n",
    "    count = 0\n",
    "    seen_content = 1\n",
    "    for c in context_words:\n",
    "      if r in glove_vectors and c[0] in glove_vectors:\n",
    "        count += glove_vectors.similarity(r, c[0])\n",
    "        seen_content += 1\n",
    "    \n",
    "    count = count / seen_content\n",
    "    \n",
    "    \n",
    "    if count >= best_count:\n",
    "      best_word = r\n",
    "      best_count = count\n",
    "\n",
    "  return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NNlSuyIYNBhr"
   },
   "outputs": [],
   "source": [
    "next_char = ['â€˜twas']\n",
    "rhyme_scheme = 'ABBCBB'\n",
    "\n",
    "one_step_model = OneStep(model)\n",
    "states = None\n",
    "\n",
    "result = [next_char]\n",
    "\n",
    "breaks = rhyme_scheme.count(\" \")\n",
    "lines = len(rhyme_scheme) - breaks\n",
    "n = 0\n",
    "prev_char = []\n",
    "\n",
    "\n",
    "while n < lines:\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  \n",
    "  if next_char == ['\\n']:\n",
    "    if prev_char != ['\\n']:\n",
    "      result.append(next_char)\n",
    "      n += 1\n",
    "  else:\n",
    "    result.append(next_char)\n",
    "    \n",
    "  prev_char = next_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GS1mNpPtKHG2",
    "outputId": "c549b121-b77d-4b7f-839f-0c2ff52f7b14"
   },
   "outputs": [],
   "source": [
    "line_count = 0\n",
    "rhymes = {}\n",
    "\n",
    "temp_scheme = rhyme_scheme.replace(\" \", \"\")\n",
    "i = 0\n",
    "start_index = 0\n",
    "for i in range(len(result)):\n",
    "  if result[i] == ['\\n']:\n",
    "    rhyme_index = temp_scheme[line_count]\n",
    "    if rhyme_index in rhymes:\n",
    "      base_rhyme_word = rhymes[rhyme_index]\n",
    "      embedding_words = result[start_index:i-1]\n",
    "      rhymed_word = get_rhyme_with_max_embedding(base_rhyme_word[0], embedding_words)\n",
    "      result[i-1] = [rhymed_word]\n",
    "      rhymes[rhyme_index] = result[i-1]\n",
    "      \n",
    "    else:\n",
    "      rhymes[rhyme_index] = result[i-1]\n",
    "    \n",
    "    start_index = i + 1\n",
    "    line_count += 1\n",
    "    \n",
    "    \n",
    "start_index = 0\n",
    "line_count = 0\n",
    "for i in range(len(result)):\n",
    "  if result[i] == ['\\n']:\n",
    "    if rhyme_scheme[line_count] == \" \":\n",
    "        result[start_index - 1] = ['\\n\\n']\n",
    "        \n",
    "    line_count += 1\n",
    "    start_index = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3K8WqG8R08A",
    "outputId": "f521e57e-f31f-4bad-e95f-3830ca2ddcdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " â€˜twas in all their ancient faces like gifts \n",
      " and may they all do their gifts \n",
      " with all untold shifts \n",
      " art thou really are the children \n",
      " as god on their joyous gifts \n",
      " blow thou little white christmas shifts \n",
      " \n"
     ]
    }
   ],
   "source": [
    "poem = \" \"\n",
    "for l in result:\n",
    "  poem += l[0]\n",
    "  poem += \" \"\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P73pmz1SSwJ9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((IndexedSlicesSpec(TensorShape([None, 512]), tf.float32, tf.int32, tf.int32, TensorShape([None])), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6fdf70>, 140667696630352), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(512, 3072), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac711670>, 140667696631120), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024, 3072), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6c0ee0>, 140667696095568), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(2, 3072), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6f6e80>, 140667696240480), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024, 12341), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac690e20>, 140667696002192), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(12341,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6a1e80>, 140667696001872), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((IndexedSlicesSpec(TensorShape([None, 512]), tf.float32, tf.int32, tf.int32, TensorShape([None])), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6fdf70>, 140667696630352), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(512, 3072), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac711670>, 140667696631120), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024, 3072), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6c0ee0>, 140667696095568), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(2, 3072), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6f6e80>, 140667696240480), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024, 12341), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac690e20>, 140667696002192), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(12341,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fefac6a1e80>, 140667696001872), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_poems/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_poems/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_poems')\n",
    "#model = keras.load_model('model_poems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
